{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "from process import Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from BTE import BTE\n",
    "from CCB import CCB\n",
    "from CETR import CETR\n",
    "from CTTD import CTTD\n",
    "from CETD import CETD\n",
    "from ConEx import ConEx\n",
    "\n",
    "bte = BTE()\n",
    "ccb = CCB()\n",
    "cetr1d = CETR(method='1D')\n",
    "cetr2d = CETR(method='2D')\n",
    "cttd = CTTD()\n",
    "cetd = CETD()\n",
    "\n",
    "conex = ConEx(line_algos=[cetr1d, cetr2d, cttd], token_algos=[bte, ccb], dom_algos=[cetd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CETD:BBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\r"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "data_dir = '../Data/processed/CETD/BBC/'\n",
    "for i, filename in enumerate(os.listdir(data_dir + 'gold/')):\n",
    "    if filename.endswith('txt'):\n",
    "        idx = filename.split('.')[0]\n",
    "        with open(data_dir + 'original/' + idx +'.htm') as f:\n",
    "            html_str = f.read().decode('iso-8859-1')\n",
    "        with open(data_dir + 'gold/' + idx +'.txt') as f:\n",
    "            content = f.read().decode('iso-8859-1').split('\\n')\n",
    "        \n",
    "        conex.process_html(html_str, tidy=False)\n",
    "        conex.run_algorithms()\n",
    "        all_ret = conex.filter_content_all()\n",
    "        \n",
    "        gold = [word for line in content for word in line.strip().split() if line.strip()]\n",
    "        for algo in all_ret.keys():\n",
    "            prec, recall, f1 = Evaluate.eval(all_ret[algo], gold)\n",
    "            if algo in results.keys():\n",
    "                results[algo].append((prec, recall, f1))\n",
    "            else:\n",
    "                results[algo] = [(prec, recall, f1)]\n",
    "        \n",
    "        print(i, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTE': array([ 0.93921188,  0.95581531,  0.94290097]),\n",
       " 'CCB': array([ 0.89459988,  0.81008134,  0.84551519]),\n",
       " 'CETD': array([ 0.73468478,  0.89988095,  0.80009244]),\n",
       " 'CETR1D': array([ 0.85239865,  0.85004629,  0.83714442]),\n",
       " 'CETR2D': array([ 0.78276652,  0.88449159,  0.81808154]),\n",
       " 'CTTD': array([ 0.58931447,  0.55722745,  0.55776566]),\n",
       " 'all-avg-1-step': array([ 0.86550776,  0.87118277,  0.86139429]),\n",
       " 'all-avg-2-steps': array([ 0.71904081,  0.94664012,  0.81036578]),\n",
       " 'all-max-1-step': array([ 0.65689622,  0.98273831,  0.77675653]),\n",
       " 'all-max-2-steps': array([ 0.65689622,  0.98273831,  0.77675653]),\n",
       " 'all-vote-1-step': array([ 0.87048804,  0.87821361,  0.86863621]),\n",
       " 'all-vote-2-steps': array([ 0.84547049,  0.89019454,  0.86219965]),\n",
       " 'line_combined-avg': array([ 0.87258148,  0.84114582,  0.84393819]),\n",
       " 'line_combined-max': array([ 0.68606331,  0.91007965,  0.77359221]),\n",
       " 'line_combined-vote': array([ 0.84401407,  0.85524224,  0.83659646]),\n",
       " 'token_combined-avg': array([ 0.96130546,  0.86747696,  0.90503638]),\n",
       " 'token_combined-max': array([ 0.8669137 ,  0.95701711,  0.90532555]),\n",
       " 'token_combined-vote': array([ 0.91554151,  0.87966884,  0.89335769])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{algo: np.average(results[algo], axis=0) for algo in results.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CETD:nytimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "process.py:112: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  table[i - 1][j - 1] + 1 if ca == cb else\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\r"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "data_dir = '../Data/processed/CETD/nytimes/'\n",
    "for i, filename in enumerate(os.listdir(data_dir + 'gold/')):\n",
    "    if filename.endswith('txt'):\n",
    "        idx = filename.split('.')[0]\n",
    "        with open(data_dir + 'original/' + idx +'.htm') as f:\n",
    "            html_str = f.read().decode('iso-8859-1')\n",
    "        with open(data_dir + 'gold/' + idx +'.txt') as f:\n",
    "            content = f.read().decode('iso-8859-1').split('\\n')\n",
    "        \n",
    "        conex.process_html(html_str, tidy=False)\n",
    "        conex.run_algorithms()\n",
    "        all_ret = conex.filter_content_all()\n",
    "        \n",
    "        gold = [word for line in content for word in line.strip().split() if line.strip()]\n",
    "        for algo in all_ret.keys():\n",
    "            prec, recall, f1 = Evaluate.eval(all_ret[algo], gold)\n",
    "            if algo in results.keys():\n",
    "                results[algo].append((prec, recall, f1))\n",
    "            else:\n",
    "                results[algo] = [(prec, recall, f1)]\n",
    "        \n",
    "        print(i, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTE': array([ 0.82115542,  0.93114144,  0.86572198]),\n",
       " 'CCB': array([ 0.91335775,  0.83961155,  0.87015548]),\n",
       " 'CETD': array([ 0.92737068,  0.79452482,  0.85022747]),\n",
       " 'CETR1D': array([ 0.87192239,  0.87991804,  0.86647123]),\n",
       " 'CETR2D': array([ 0.80867971,  0.92967694,  0.85790448]),\n",
       " 'CTTD': array([ 0.92580026,  0.83892478,  0.87734837]),\n",
       " 'all-avg-1-step': array([ 0.93557637,  0.89590904,  0.91410915]),\n",
       " 'all-avg-2-steps': array([ 0.83774473,  0.94265748,  0.88336155]),\n",
       " 'all-max-1-step': array([ 0.72181405,  0.95372163,  0.81622326]),\n",
       " 'all-max-2-steps': array([ 0.72181405,  0.95372163,  0.81622326]),\n",
       " 'all-vote-1-step': array([ 0.90889843,  0.90411295,  0.90417706]),\n",
       " 'all-vote-2-steps': array([ 0.91279123,  0.90945525,  0.90912303]),\n",
       " 'line_combined-avg': array([ 0.92657928,  0.87452874,  0.8974939 ]),\n",
       " 'line_combined-max': array([ 0.78204401,  0.93412788,  0.84386961]),\n",
       " 'line_combined-vote': array([ 0.88879577,  0.89633802,  0.88684434]),\n",
       " 'token_combined-avg': array([ 0.86589755,  0.88256528,  0.86826333]),\n",
       " 'token_combined-max': array([ 0.81675361,  0.93117891,  0.86352094]),\n",
       " 'token_combined-vote': array([ 0.85730184,  0.88474575,  0.86608409])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{algo: np.average(results[algo], axis=0) for algo in results.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CETD:ars technica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "process.py:113: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  table[i - 1][j - 1] + 1 if ca == cb else\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\r"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "data_dir = '../Data/processed/CETD/arstechnica/'\n",
    "for i, filename in enumerate(os.listdir(data_dir + 'gold/')):\n",
    "    if filename.endswith('txt'):\n",
    "        idx = filename.split('.')[0]\n",
    "        with open(data_dir + 'original/' + idx +'.htm') as f:\n",
    "            html_str = f.read().decode('iso-8859-1')\n",
    "        with open(data_dir + 'gold/' + idx +'.txt') as f:\n",
    "            content = f.read().decode('iso-8859-1').split('\\n')\n",
    "        \n",
    "        conex.process_html(html_str, tidy=False)\n",
    "        conex.run_algorithms()\n",
    "        all_ret = conex.filter_content_all()\n",
    "        \n",
    "        gold = [word for line in content for word in line.strip().split() if line.strip()]\n",
    "        for algo in all_ret.keys():\n",
    "            prec, recall, f1 = Evaluate.eval(all_ret[algo], gold)\n",
    "            if algo in results.keys():\n",
    "                results[algo].append((prec, recall, f1))\n",
    "            else:\n",
    "                results[algo] = [(prec, recall, f1)]\n",
    "        \n",
    "        print(i, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTE': array([ 0.97096249,  0.98648634,  0.9783888 ]),\n",
       " 'CCB': array([ 0.87116918,  0.93735405,  0.90210106]),\n",
       " 'CETD': array([ 0.8835689 ,  0.81030651,  0.84090206]),\n",
       " 'CETR1D': array([ 0.93231718,  0.94047597,  0.92801146]),\n",
       " 'CETR2D': array([ 0.81077829,  0.96278048,  0.86609205]),\n",
       " 'CTTD': array([ 0.98630877,  0.91045713,  0.94401413]),\n",
       " 'all-avg-1-step': array([ 0.98622921,  0.95897257,  0.97188904]),\n",
       " 'all-avg-2-steps': array([ 0.88631883,  0.98332532,  0.92824933]),\n",
       " 'all-max-1-step': array([ 0.74208575,  0.98705576,  0.84045442]),\n",
       " 'all-max-2-steps': array([ 0.74208575,  0.98705576,  0.84045442]),\n",
       " 'all-vote-1-step': array([ 0.9633101 ,  0.96212577,  0.96125425]),\n",
       " 'all-vote-2-steps': array([ 0.95948156,  0.96453942,  0.96033252]),\n",
       " 'line_combined-avg': array([ 0.97786591,  0.94383944,  0.9588535 ]),\n",
       " 'line_combined-max': array([ 0.80855274,  0.97469751,  0.8714887 ]),\n",
       " 'line_combined-vote': array([ 0.92979808,  0.94927654,  0.93183196]),\n",
       " 'token_combined-avg': array([ 0.98284287,  0.95757223,  0.96943523]),\n",
       " 'token_combined-max': array([ 0.86244556,  0.98661792,  0.91902328]),\n",
       " 'token_combined-vote': array([ 0.91887948,  0.96181764,  0.93932569])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{algo: np.average(results[algo], axis=0) for algo in results.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CETD:Yahoo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\r"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "data_dir = '../Data/processed/CETD/YAHOO!/'\n",
    "for i, filename in enumerate(os.listdir(data_dir + 'gold/')):\n",
    "    if filename.endswith('txt'):\n",
    "        idx = filename.split('.')[0]\n",
    "        with open(data_dir + 'original/' + idx +'.htm') as f:\n",
    "            html_str = f.read().decode('iso-8859-1')\n",
    "        with open(data_dir + 'gold/' + idx +'.txt') as f:\n",
    "            content = f.read().decode('iso-8859-1').split('\\n')\n",
    "        \n",
    "        conex.process_html(html_str, tidy=False)\n",
    "        conex.run_algorithms()\n",
    "        all_ret = conex.filter_content_all()\n",
    "        \n",
    "        gold = [word for line in content for word in line.strip().split() if line.strip()]\n",
    "        for algo in all_ret.keys():\n",
    "            prec, recall, f1 = Evaluate.eval(all_ret[algo], gold)\n",
    "            if algo in results.keys():\n",
    "                results[algo].append((prec, recall, f1))\n",
    "            else:\n",
    "                results[algo] = [(prec, recall, f1)]\n",
    "        \n",
    "        print(i, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTE': array([ 0.59281714,  0.96465043,  0.72157413]),\n",
       " 'CCB': array([ 0.96408698,  0.79440368,  0.86551152]),\n",
       " 'CETD': array([ 0.68867809,  0.86817467,  0.75745881]),\n",
       " 'CETR1D': array([ 0.77064064,  0.82349776,  0.76610224]),\n",
       " 'CETR2D': array([ 0.68382853,  0.94707974,  0.78165433]),\n",
       " 'CTTD': array([ 0.73925093,  0.90140071,  0.80606386]),\n",
       " 'all-avg-1-step': array([ 0.82024832,  0.94216251,  0.87025514]),\n",
       " 'all-avg-2-steps': array([ 0.56550564,  0.97271887,  0.70501238]),\n",
       " 'all-max-1-step': array([ 0.5223675 ,  0.97706845,  0.66980741]),\n",
       " 'all-max-2-steps': array([ 0.5223675 ,  0.97706845,  0.66980741]),\n",
       " 'all-vote-1-step': array([ 0.78816707,  0.933954  ,  0.84755276]),\n",
       " 'all-vote-2-steps': array([ 0.76076767,  0.92641339,  0.82843479]),\n",
       " 'line_combined-avg': array([ 0.77483868,  0.92818526,  0.83292886]),\n",
       " 'line_combined-max': array([ 0.58625785,  0.96841346,  0.71872263]),\n",
       " 'line_combined-vote': array([ 0.7677533 ,  0.93423324,  0.82967597]),\n",
       " 'token_combined-avg': array([ 0.78270024,  0.8977872 ,  0.83051736]),\n",
       " 'token_combined-max': array([ 0.59130399,  0.96465043,  0.72070647]),\n",
       " 'token_combined-vote': array([ 0.708161  ,  0.88287051,  0.77817061])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{algo: np.average(results[algo], axis=0) for algo in results.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CETD:Chaos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "process.py:113: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  table[i - 1][j - 1] + 1 if ca == cb else\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\r"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "data_dir = '../Data/processed/CETD/Chaos/'\n",
    "for i, filename in enumerate(os.listdir(data_dir + 'gold/')):\n",
    "    if filename.endswith('txt'):\n",
    "        idx = filename.split('.')[0]\n",
    "        with open(data_dir + 'original/' + idx +'.htm') as f:\n",
    "            html_str = f.read().decode('iso-8859-1')\n",
    "        with open(data_dir + 'gold/' + idx +'.txt') as f:\n",
    "            content = f.read().decode('iso-8859-1').split('\\n')\n",
    "        \n",
    "        conex.process_html(html_str, tidy=False)\n",
    "        conex.run_algorithms()\n",
    "        all_ret = conex.filter_content_all()\n",
    "        \n",
    "        gold = [word for line in content for word in line.strip().split() if line.strip()]\n",
    "        for algo in all_ret.keys():\n",
    "            prec, recall, f1 = Evaluate.eval(all_ret[algo], gold)\n",
    "            if algo in results.keys():\n",
    "                results[algo].append((prec, recall, f1))\n",
    "            else:\n",
    "                results[algo] = [(prec, recall, f1)]\n",
    "        \n",
    "        print(i, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTE': array([ 0.90066523,  0.9430242 ,  0.91726447]),\n",
       " 'CCB': array([ 0.94101424,  0.87165613,  0.89878125]),\n",
       " 'CETD': array([ 0.77750083,  0.7148469 ,  0.72887722]),\n",
       " 'CETR1D': array([ 0.8715585 ,  0.89809567,  0.87193145]),\n",
       " 'CETR2D': array([ 0.8158171 ,  0.92544199,  0.85382835]),\n",
       " 'CTTD': array([ 0.88989039,  0.84748194,  0.85755649]),\n",
       " 'all-avg-1-step': array([ 0.92151331,  0.92162518,  0.91849676]),\n",
       " 'all-avg-2-steps': array([ 0.81624285,  0.94863273,  0.87051283]),\n",
       " 'all-max-1-step': array([ 0.72887403,  0.95793069,  0.81703383]),\n",
       " 'all-max-2-steps': array([ 0.72887403,  0.95793069,  0.81703383]),\n",
       " 'all-vote-1-step': array([ 0.91811601,  0.92122956,  0.91679614]),\n",
       " 'all-vote-2-steps': array([ 0.90690548,  0.9208341 ,  0.91096333]),\n",
       " 'line_combined-avg': array([ 0.88649862,  0.90751321,  0.88850865]),\n",
       " 'line_combined-max': array([ 0.78162754,  0.93938268,  0.84062508]),\n",
       " 'line_combined-vote': array([ 0.86236128,  0.91125894,  0.87543121]),\n",
       " 'token_combined-avg': array([ 0.92915867,  0.91384062,  0.91756877]),\n",
       " 'token_combined-max': array([ 0.89086973,  0.94356166,  0.91247828]),\n",
       " 'token_combined-vote': array([ 0.91566519,  0.90709254,  0.90775399])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{algo: np.average(results[algo], axis=0) for algo in results.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CETD:wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\r"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "data_dir = '../Data/processed/CETD/wiki/'\n",
    "for i, filename in enumerate(os.listdir(data_dir + 'gold/')):\n",
    "    if filename.endswith('txt'):\n",
    "        idx = filename.split('.')[0]\n",
    "        with open(data_dir + 'original/' + idx +'.htm') as f:\n",
    "            html_str = f.read().decode('iso-8859-1')\n",
    "        with open(data_dir + 'gold/' + idx +'.txt') as f:\n",
    "            content = f.read().decode('iso-8859-1').split('\\n')\n",
    "        \n",
    "        conex.process_html(html_str, tidy=False)\n",
    "        conex.run_algorithms()\n",
    "        all_ret = conex.filter_content_all()\n",
    "        \n",
    "        gold = [word for line in content for word in line.strip().split() if line.strip()]\n",
    "        for algo in all_ret.keys():\n",
    "            prec, recall, f1 = Evaluate.eval(all_ret[algo], gold)\n",
    "            if algo in results.keys():\n",
    "                results[algo].append((prec, recall, f1))\n",
    "            else:\n",
    "                results[algo] = [(prec, recall, f1)]\n",
    "        \n",
    "        print(i, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTE': array([ 0.87345983,  0.7801749 ,  0.81200457]),\n",
       " 'CCB': array([ 0.90438472,  0.6240331 ,  0.72795798]),\n",
       " 'CETD': array([ 0.80764631,  0.3186852 ,  0.4503254 ]),\n",
       " 'CETR1D': array([ 0.86983977,  0.67788724,  0.74938399]),\n",
       " 'CETR2D': array([ 0.85404426,  0.76292837,  0.79661454]),\n",
       " 'CTTD': array([ 0.87670004,  0.70507747,  0.77712501]),\n",
       " 'all-avg-1-step': array([ 0.8756231 ,  0.72443062,  0.78601244]),\n",
       " 'all-avg-2-steps': array([ 0.85858603,  0.84380078,  0.84932071]),\n",
       " 'all-max-1-step': array([ 0.84205482,  0.91594722,  0.87619787]),\n",
       " 'all-max-2-steps': array([ 0.84205482,  0.91594722,  0.87619787]),\n",
       " 'all-vote-1-step': array([ 0.88042524,  0.71050509,  0.77950417]),\n",
       " 'all-vote-2-steps': array([ 0.88294705,  0.69865967,  0.77382993]),\n",
       " 'line_combined-avg': array([ 0.86385568,  0.73978173,  0.79123575]),\n",
       " 'line_combined-max': array([ 0.85216479,  0.85067025,  0.84887774]),\n",
       " 'line_combined-vote': array([ 0.86354969,  0.72591769,  0.78002891]),\n",
       " 'token_combined-avg': array([ 0.89332517,  0.69778408,  0.7734723 ]),\n",
       " 'token_combined-max': array([ 0.87334586,  0.79079046,  0.81912538]),\n",
       " 'token_combined-vote': array([ 0.88601615,  0.70150035,  0.77329072])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{algo: np.average(results[algo], axis=0) for algo in results.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dragnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1371\r"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "data_dir = '../Data/processed/Dragnet/'\n",
    "for i, filename in enumerate(os.listdir(data_dir + 'Corrected/')):\n",
    "    if filename.endswith('txt'):\n",
    "        idx = filename.split('.')[0]\n",
    "        with open(data_dir + 'HTML/' + idx +'.html') as f:\n",
    "            html_str = f.read().decode('iso-8859-1')\n",
    "        with open(data_dir + 'Corrected/' + idx +'.html.corrected.txt') as f:\n",
    "            content = f.read().decode('iso-8859-1').split('\\n')\n",
    "        \n",
    "        conex.process_html(html_str, tidy=False)\n",
    "        conex.run_algorithms()\n",
    "        all_ret = conex.filter_content_all()\n",
    "        \n",
    "        gold = [word for line in content for word in line.strip().split() if line.strip()]\n",
    "        for algo in all_ret.keys():\n",
    "            prec, recall, f1 = Evaluate.eval(all_ret[algo], gold)\n",
    "            if algo in results.keys():\n",
    "                results[algo].append((prec, recall, f1))\n",
    "            else:\n",
    "                results[algo] = [(prec, recall, f1)]\n",
    "        \n",
    "        print(i, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTE': array([ 0.74868951,  0.91665729,  0.79561729]),\n",
       " 'CCB': array([ 0.79164479,  0.76643866,  0.75246321]),\n",
       " 'CETD': array([ 0.64592535,  0.88018379,  0.71611616]),\n",
       " 'CETR1D': array([ 0.69074577,  0.89203131,  0.73293374]),\n",
       " 'CETR2D': array([ 0.63602928,  0.93290607,  0.70941767]),\n",
       " 'CTTD': array([ 0.71269299,  0.83335844,  0.72073838]),\n",
       " 'all-avg-1-step': array([ 0.72542111,  0.9108238 ,  0.77289632]),\n",
       " 'all-avg-2-steps': array([ 0.6045421 ,  0.95978686,  0.70253527]),\n",
       " 'all-max-1-step': array([ 0.54136627,  0.97751887,  0.65715644]),\n",
       " 'all-max-2-steps': array([ 0.54136627,  0.97751887,  0.65715644]),\n",
       " 'all-vote-1-step': array([ 0.72219831,  0.90733493,  0.77113788]),\n",
       " 'all-vote-2-steps': array([ 0.71896471,  0.90859441,  0.7739115 ]),\n",
       " 'line_combined-avg': array([ 0.69653367,  0.8963998 ,  0.73737321]),\n",
       " 'line_combined-max': array([ 0.59660074,  0.94603029,  0.68563805]),\n",
       " 'line_combined-vote': array([ 0.67868415,  0.9087497 ,  0.73015178]),\n",
       " 'token_combined-avg': array([ 0.78026512,  0.84667342,  0.78610819]),\n",
       " 'token_combined-max': array([ 0.72767891,  0.92275694,  0.78513462]),\n",
       " 'token_combined-vote': array([ 0.76800121,  0.83987429,  0.77582004])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{algo: np.average(results[algo], axis=0) for algo in results.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L3S-GN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601\r"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "data_dir = '../Data/processed/L3S-GN1/'\n",
    "for i, filename in enumerate(os.listdir(data_dir + 'annotated/')):\n",
    "    if filename.endswith('txt'):\n",
    "        idx = filename.split('.')[0]\n",
    "        with open(data_dir + 'original/' + idx +'.html') as f:\n",
    "            html_str = f.read().decode('iso-8859-1')\n",
    "        with open(data_dir + 'annotated/' + idx +'.txt') as f:\n",
    "            content = f.read().decode('iso-8859-1').split('\\n')\n",
    "        \n",
    "        conex.process_html(html_str, tidy=False)\n",
    "        conex.run_algorithms()\n",
    "        all_ret = conex.filter_content_all()\n",
    "        \n",
    "        gold = [word for line in content for word in line.strip().split() if line.strip()]\n",
    "        for algo in all_ret.keys():\n",
    "            prec, recall, f1 = Evaluate.eval(all_ret[algo], gold)\n",
    "            if algo in results.keys():\n",
    "                results[algo].append((prec, recall, f1))\n",
    "            else:\n",
    "                results[algo] = [(prec, recall, f1)]\n",
    "        \n",
    "        print(i, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTE': array([ 0.85405799,  0.95009084,  0.88242951]),\n",
       " 'CCB': array([ 0.88795241,  0.83181282,  0.84478259]),\n",
       " 'CETD': array([ 0.5982342 ,  0.94332478,  0.7069186 ]),\n",
       " 'CETR1D': array([ 0.82503273,  0.92472403,  0.85224148]),\n",
       " 'CETR2D': array([ 0.75704568,  0.95362865,  0.81975359]),\n",
       " 'CTTD': array([ 0.79666377,  0.89159694,  0.81607117]),\n",
       " 'all-avg-1-step': array([ 0.8511802 ,  0.93857179,  0.87857296]),\n",
       " 'all-avg-2-steps': array([ 0.71818503,  0.97398768,  0.80460969]),\n",
       " 'all-max-1-step': array([ 0.64356897,  0.98267502,  0.75350208]),\n",
       " 'all-max-2-steps': array([ 0.64356897,  0.98267502,  0.75350208]),\n",
       " 'all-vote-1-step': array([ 0.80901227,  0.94283494,  0.85196543]),\n",
       " 'all-vote-2-steps': array([ 0.7808582 ,  0.94752881,  0.8347665 ]),\n",
       " 'line_combined-avg': array([ 0.81751826,  0.92477323,  0.84570192]),\n",
       " 'line_combined-max': array([ 0.69928279,  0.96271595,  0.78428751]),\n",
       " 'line_combined-vote': array([ 0.8040528 ,  0.93298493,  0.84126321]),\n",
       " 'token_combined-avg': array([ 0.87908044,  0.89774668,  0.87400075]),\n",
       " 'token_combined-max': array([ 0.83046383,  0.95206163,  0.8691186 ]),\n",
       " 'token_combined-vote': array([ 0.86363558,  0.8916263 ,  0.86348148])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{algo: np.average(results[algo], axis=0) for algo in results.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CleanEval-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\r"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "data_dir = '../Data/processed/CleanEval/'\n",
    "for i, filename in enumerate(os.listdir(data_dir + 'en-cleaned/')):\n",
    "    if filename.endswith('txt'):\n",
    "        idx = filename.split('.')[0]\n",
    "        with open(data_dir + 'en-original/' + idx +'.html') as f:\n",
    "            html_str = f.read().decode('iso-8859-1')\n",
    "        with open(data_dir + 'en-cleaned/' + idx +'.txt') as f:\n",
    "            content = f.read().decode('iso-8859-1').split('\\n')\n",
    "        \n",
    "        conex.process_html(html_str, tidy=True)\n",
    "        conex.run_algorithms()\n",
    "        all_ret = conex.filter_content_all()\n",
    "        \n",
    "        gold = [word for line in content for word in line.strip().split() if line.strip()]\n",
    "        for algo in all_ret.keys():\n",
    "            prec, recall, f1 = Evaluate.eval(all_ret[algo], gold)\n",
    "            if algo in results.keys():\n",
    "                results[algo].append((prec, recall, f1))\n",
    "            else:\n",
    "                results[algo] = [(prec, recall, f1)]\n",
    "        \n",
    "        print(i, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTE': array([ 0.85570409,  0.89933882,  0.86415911]),\n",
       " 'CCB': array([ 0.87075692,  0.78819132,  0.80934205]),\n",
       " 'CETD': array([ 0.79981607,  0.85993219,  0.80951209]),\n",
       " 'CETR1D': array([ 0.89487375,  0.80258472,  0.83545206]),\n",
       " 'CETR2D': array([ 0.87705652,  0.85718623,  0.85429851]),\n",
       " 'CTTD': array([ 0.83217694,  0.71959895,  0.7598828 ]),\n",
       " 'all-avg-1-step': array([ 0.88890009,  0.8646296 ,  0.87107716]),\n",
       " 'all-avg-2-steps': array([ 0.8273911 ,  0.91666305,  0.85983351]),\n",
       " 'all-max-1-step': array([ 0.80112415,  0.93593292,  0.85114089]),\n",
       " 'all-max-2-steps': array([ 0.80112415,  0.93593292,  0.85114089]),\n",
       " 'all-vote-1-step': array([ 0.86885447,  0.86585291,  0.85904792]),\n",
       " 'all-vote-2-steps': array([ 0.86011024,  0.88790304,  0.8645855 ]),\n",
       " 'line_combined-avg': array([ 0.89280297,  0.81456932,  0.8443148 ]),\n",
       " 'line_combined-max': array([ 0.83535016,  0.8819579 ,  0.84610083]),\n",
       " 'line_combined-vote': array([ 0.89360986,  0.81872745,  0.84570734]),\n",
       " 'token_combined-avg': array([ 0.85896691,  0.85859299,  0.8496011 ]),\n",
       " 'token_combined-max': array([ 0.84349867,  0.90366551,  0.8621409 ]),\n",
       " 'token_combined-vote': array([ 0.855389  ,  0.84304426,  0.8394724 ])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{algo: np.average(results[algo], axis=0) for algo in results.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CleanEval:final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\r"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "data_dir = '../Data/processed/CleanEval/'\n",
    "for i, filename in enumerate(os.listdir(data_dir + 'final-cleaned/')):\n",
    "    if filename.endswith('txt'):\n",
    "        idx = filename.split('.')[0]\n",
    "        with open(data_dir + 'final-original/' + idx +'.html') as f:\n",
    "            html_str = f.read().decode('iso-8859-1')\n",
    "        with open(data_dir + 'final-cleaned/' + idx +'.txt') as f:\n",
    "            content = f.read().decode('iso-8859-1').split('\\n')\n",
    "        \n",
    "        conex.process_html(html_str, tidy=True)\n",
    "        conex.run_algorithms()\n",
    "        all_ret = conex.filter_content_all()\n",
    "        \n",
    "        gold = [word for line in content for word in line.strip().split() if line.strip()]\n",
    "        for algo in all_ret.keys():\n",
    "            prec, recall, f1 = Evaluate.eval(all_ret[algo], gold)\n",
    "            if algo in results.keys():\n",
    "                results[algo].append((prec, recall, f1))\n",
    "            else:\n",
    "                results[algo] = [(prec, recall, f1)]\n",
    "        \n",
    "        print(i, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTE': array([ 0.89063879,  0.92991102,  0.89570684]),\n",
       " 'CCB': array([ 0.88782537,  0.83646263,  0.84601318]),\n",
       " 'CETD': array([ 0.8466789 ,  0.85398688,  0.82644754]),\n",
       " 'CETR1D': array([ 0.91636741,  0.83533537,  0.85759074]),\n",
       " 'CETR2D': array([ 0.90373113,  0.8793865 ,  0.87599108]),\n",
       " 'CTTD': array([ 0.88157824,  0.793527  ,  0.81844896]),\n",
       " 'all-avg-1-step': array([ 0.90781097,  0.90556457,  0.89572026]),\n",
       " 'all-avg-2-steps': array([ 0.87560928,  0.95102902,  0.89937423]),\n",
       " 'all-max-1-step': array([ 0.85029347,  0.96406402,  0.88971233]),\n",
       " 'all-max-2-steps': array([ 0.85029347,  0.96406402,  0.88971233]),\n",
       " 'all-vote-1-step': array([ 0.90159884,  0.89600335,  0.88681362]),\n",
       " 'all-vote-2-steps': array([ 0.89448608,  0.90805407,  0.8882213 ]),\n",
       " 'line_combined-avg': array([ 0.908182  ,  0.85404513,  0.86539411]),\n",
       " 'line_combined-max': array([ 0.87750011,  0.91547179,  0.88144211]),\n",
       " 'line_combined-vote': array([ 0.91121344,  0.85632853,  0.86816243]),\n",
       " 'token_combined-avg': array([ 0.88797446,  0.88445165,  0.87311995]),\n",
       " 'token_combined-max': array([ 0.88755766,  0.9320573 ,  0.89511075]),\n",
       " 'token_combined-vote': array([ 0.90137637,  0.88314194,  0.87543811])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{algo: np.average(results[algo], axis=0) for algo in results.keys()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
